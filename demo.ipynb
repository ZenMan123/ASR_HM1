{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e0478ca",
   "metadata": {},
   "source": [
    "# Демонстрация инференса обученной модели для задачи ASR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acafb150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Клонируем репозиторий\n",
    "!git clone https://github.com/ZenMan67/..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6daa7b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ставим все необходимые библиотеки\n",
    "!pip install -r .../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba9a2b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.mlspace/envs/zenman67_tmp/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/jovyan/.mlspace/envs/zenman67_tmp/lib/python3.11/site-packages/huggingface_hub/file_download.py:982: UserWarning: `local_dir_use_symlinks` parameter is deprecated and will be ignored. The process to download files to a local folder has been updated and do not rely on symlinks anymore. You only need to pass a destination folder as`local_dir`.\n",
      "For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/download#download-files-to-local-folder.\n",
      "  warnings.warn(\n",
      "Fetching 6 files: 100%|██████████| 6/6 [00:11<00:00,  1.88s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/zenman67/training/proj/saved/asr_checkpoint_v1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Подгружаем финальную модельку\n",
    "\n",
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "snapshot_download(\n",
    "    repo_id=\"ZenMan67/asr_checkpoint_v1\",\n",
    "    repo_type=\"model\",\n",
    "    local_dir=\"saved/asr_checkpoint_v1\",\n",
    "    local_dir_use_symlinks=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8725b7",
   "metadata": {},
   "source": [
    "Поддержку скачивания данных по ссылке завезти не успел:("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a9cc235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.mlspace/envs/zenman67_tmp/lib/python3.11/site-packages/torch_audiomentations/core/transforms_interface.py:76: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:\n",
      "  >>> augment = Gain(..., output_type='dict')\n",
      "  >>> augmented_samples = augment(samples).samples\n",
      "  warnings.warn(\n",
      "ConformerModel(\n",
      "  (subsample): ConvSubsampling(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2d(1, 256, kernel_size=(3, 3), stride=(1, 2), padding=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 2), padding=(1, 1))\n",
      "      (3): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (pre_proj): LinearProjection(\n",
      "    (proj): Linear(in_features=65536, out_features=512, bias=True)\n",
      "  )\n",
      "  (pos_enc): RelativePositionalEncoding()\n",
      "  (blocks): ModuleList(\n",
      "    (0-15): 16 x ConformerBlock(\n",
      "      (ff1): FeedForwardModule(\n",
      "        (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (swish): Swish()\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (mhsa): MultiHeadSelfAttention(\n",
      "        (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (conv): ConformerConvModule(\n",
      "        (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (pw_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
      "        (glu): GLU(dim=1)\n",
      "        (dw_conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)\n",
      "        (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (swish): Swish()\n",
      "        (pw_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ff2): FeedForwardModule(\n",
      "        (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (swish): Swish()\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (final_ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (ctc_head): Linear(in_features=512, out_features=4001, bias=True)\n",
      ")\n",
      "All parameters: 133758881\n",
      "Trainable parameters: 133758881\n",
      "[2025-10-16 23:34:42,216][torchaudio.utils.download][INFO] - The local file (/home/jovyan/.cache/torch/hub/torchaudio/decoder-assets/librispeech-4-gram/lexicon.txt) exists. Skipping the download.\n",
      "[2025-10-16 23:34:42,218][torchaudio.utils.download][INFO] - The local file (/home/jovyan/.cache/torch/hub/torchaudio/decoder-assets/librispeech-4-gram/tokens.txt) exists. Skipping the download.\n",
      "[2025-10-16 23:34:42,219][torchaudio.utils.download][INFO] - The local file (/home/jovyan/.cache/torch/hub/torchaudio/decoder-assets/librispeech-4-gram/lm.bin) exists. Skipping the download.\n",
      "[2025-10-16 23:34:42,524][pyctcdecode.decoder][WARNING] - Unigrams not provided and cannot be automatically determined from LM file (only arpa format). Decoding accuracy might be reduced.\n",
      "[2025-10-16 23:34:42,525][pyctcdecode.alphabet][INFO] - Alphabet determined to be of BPE style.\n",
      "[2025-10-16 23:34:42,526][pyctcdecode.alphabet][INFO] - Found <unk> in vocabulary, substituting with ▁⁇▁.\n",
      "[2025-10-16 23:34:42,527][pyctcdecode.language_model][WARNING] - No known unigrams provided, decoding results might be a lot worse.\n",
      "[2025-10-16 23:34:42,529][torchaudio.utils.download][INFO] - The local file (/home/jovyan/.cache/torch/hub/torchaudio/decoder-assets/librispeech-4-gram/lexicon.txt) exists. Skipping the download.\n",
      "[2025-10-16 23:34:42,530][torchaudio.utils.download][INFO] - The local file (/home/jovyan/.cache/torch/hub/torchaudio/decoder-assets/librispeech-4-gram/tokens.txt) exists. Skipping the download.\n",
      "[2025-10-16 23:34:42,531][torchaudio.utils.download][INFO] - The local file (/home/jovyan/.cache/torch/hub/torchaudio/decoder-assets/librispeech-4-gram/lm.bin) exists. Skipping the download.\n",
      "[2025-10-16 23:34:42,788][pyctcdecode.decoder][WARNING] - Unigrams not provided and cannot be automatically determined from LM file (only arpa format). Decoding accuracy might be reduced.\n",
      "[2025-10-16 23:34:42,789][pyctcdecode.alphabet][INFO] - Alphabet determined to be of BPE style.\n",
      "[2025-10-16 23:34:42,790][pyctcdecode.alphabet][INFO] - Found <unk> in vocabulary, substituting with ▁⁇▁.\n",
      "[2025-10-16 23:34:42,790][pyctcdecode.language_model][WARNING] - No known unigrams provided, decoding results might be a lot worse.\n",
      "Loading model weights from: saved/asr_checkpoint_v1/model_best.pth ...\n",
      "test:   0%|                                               | 0/3 [00:00<?, ?it/s]{'get_spectrogram': MelSpectrogram(\n",
      "  (spectrogram): Spectrogram()\n",
      "  (mel_scale): MelScale()\n",
      ")}\n",
      "{'get_spectrogram': MelSpectrogram(\n",
      "  (spectrogram): Spectrogram()\n",
      "  (mel_scale): MelScale()\n",
      ")}\n",
      "{'get_spectrogram': MelSpectrogram(\n",
      "  (spectrogram): Spectrogram()\n",
      "  (mel_scale): MelScale()\n",
      ")}\n",
      "test: 100%|███████████████████████████████████████| 3/3 [00:00<00:00,  3.99it/s]\n",
      "    test_CER_(Argmax): 0.16568339408412938\n",
      "    test_WER_(Argmax): 0.20005175983436851\n"
     ]
    }
   ],
   "source": [
    "# Переходим в нужную папочку и запускаем замер\n",
    "!(cd proj && python inference.py datasets.test.audio_dir=\"test_dataset/audio\" \\\n",
    "    datasets.test.transcription_dir=\"test_dataset/transcriptions\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zenman67_tmp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
